{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/21 下午6:12\n",
    "# @Author  : play4fun\n",
    "# @File    : 长方形1.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "长方形1.py:\n",
    "\n",
    "https://stackoverflow.com/questions/42262198/4-point-persective-transform-failure\n",
    "透视变换矩阵\n",
    "\n",
    "[[[183 199]]\n",
    " [[ 69 214]]\n",
    " [[ 97 390]]\n",
    " [[210 373]]]\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_euler_distance(pt1, pt2):\n",
    "    return ((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2) ** 0.5\n",
    "\n",
    "\n",
    "img22 = cv2.imread('img/subtract2.jpg')\n",
    "\n",
    "# src_pts = np.array([[8, 136], [415, 52], [420, 152], [14, 244]], dtype=np.float32)\n",
    "\n",
    "src_pts = np.array([[[97, 390], [210, 373], [183, 199], [69, 214]]], dtype=np.float32)\n",
    "# src_pts = np.array([[ [210, 373], [183, 199], [69, 214],[97, 390]]], dtype=np.float32)\n",
    "\n",
    "width = get_euler_distance(src_pts[0][0], src_pts[0][1])\n",
    "height = get_euler_distance(src_pts[0][0], src_pts[0][3])\n",
    "\n",
    "dst_pts = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warp = cv2.warpPerspective(img22, M, (int(width), int(height)))\n",
    "\n",
    "warp=cv2.flip(warp,flipCode=1)\n",
    "\n",
    "cv2.imshow('src', img22)\n",
    "cv2.imshow('warp', warp)\n",
    "# cv2.imwrite('crop0.jpg',warp)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/21 下午6:12\n",
    "# @Author  : play4fun\n",
    "# @File    : 长方形1.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "长方形1.py:\n",
    "[[[183 199]]\n",
    " [[ 69 214]]\n",
    " [[ 97 390]]\n",
    " [[210 373]]]\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img22 = cv2.imread('img/subtract2.jpg')\n",
    "\n",
    "# src_pts = np.array([[8, 136], [415, 52], [420, 152], [14, 244]], dtype=np.float32)\n",
    "\n",
    "src_pts = np.array([[[97, 390], [210, 373], [183, 199], [69, 214]]], dtype=np.float32)\n",
    "\n",
    "dst_pts = np.array([[0, 0], [50, 0], [50, 100], [0, 100]], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warp = cv2.warpPerspective(img22, M, (50, 100))\n",
    "\n",
    "cv2.imshow('src', img22)\n",
    "cv2.imshow('warp', warp)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/21 上午10:57\n",
    "# @Author  : play4fun\n",
    "# @File    : 图像相减3.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "图像相减3.py:\n",
    "\n",
    "3张图片\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "\n",
    "def diff(img, img1):  # returns just the difference of the two images\n",
    "    return cv2.absdiff(img, img1)\n",
    "\n",
    "\n",
    "def diff_remove_bg(img0, img, img1):  # removes the background but requires three images\n",
    "    d1 = diff(img0, img)\n",
    "    d2 = diff(img, img1)\n",
    "    return cv2.bitwise_and(d1, d2)\n",
    "\n",
    "\n",
    "# img1=cv2.imread('subtract1.jpg')\n",
    "img1 = cv2.imread('img/subtract1.jpg', 0)  # 灰度图\n",
    "# img2=cv2.imread('subtract2.jpg')\n",
    "img2 = cv2.imread('img/subtract2.jpg', 0)\n",
    "\n",
    "cv2.imshow('subtract1', img1)\n",
    "cv2.imshow('subtract2', img2)\n",
    "\n",
    "#st = diff_remove_bg(img2, img1,img2)\n",
    "st = diff(img2, img1)\n",
    "\n",
    "cv2.imshow('after subtract', st)\n",
    "\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/21 上午10:48\n",
    "# @Author  : play4fun\n",
    "# @File    : 图像相减1.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "图像相减1.py:\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# img1=cv2.imread('subtract1.jpg')\n",
    "img1=cv2.imread('img/subtract1.jpg',0)#灰度图\n",
    "# img2=cv2.imread('subtract2.jpg')\n",
    "img2=cv2.imread('img/subtract2.jpg',0)\n",
    "\n",
    "cv2.imshow('subtract1',img1)\n",
    "cv2.imshow('subtract2',img2)\n",
    "\n",
    "#\n",
    "st=img2-img1\n",
    "# st=img1-img2#相反\n",
    "cv2.imshow('after subtract',st)\n",
    "\n",
    "#效果好一点\n",
    "#ret,threshold=cv2.threshold(st,0, 127, cv2.THRESH_BINARY)\n",
    "ret,threshold=cv2.threshold(st, 50,255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('after threshold', threshold)\n",
    "\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[178 199]]\n",
      "\n",
      " [[177 200]]\n",
      "\n",
      " [[168 200]]\n",
      "\n",
      " [[167 201]]\n",
      "\n",
      " [[160 201]]\n",
      "\n",
      " [[159 202]]\n",
      "\n",
      " [[151 202]]\n",
      "\n",
      " [[150 203]]\n",
      "\n",
      " [[142 203]]\n",
      "\n",
      " [[141 204]]\n",
      "\n",
      " [[133 204]]\n",
      "\n",
      " [[132 205]]\n",
      "\n",
      " [[125 205]]\n",
      "\n",
      " [[124 206]]\n",
      "\n",
      " [[117 206]]\n",
      "\n",
      " [[116 207]]\n",
      "\n",
      " [[108 207]]\n",
      "\n",
      " [[107 208]]\n",
      "\n",
      " [[100 208]]\n",
      "\n",
      " [[ 99 209]]\n",
      "\n",
      " [[ 92 209]]\n",
      "\n",
      " [[ 91 210]]\n",
      "\n",
      " [[ 83 210]]\n",
      "\n",
      " [[ 82 211]]\n",
      "\n",
      " [[ 74 211]]\n",
      "\n",
      " [[ 73 212]]\n",
      "\n",
      " [[ 72 212]]\n",
      "\n",
      " [[ 71 213]]\n",
      "\n",
      " [[ 70 213]]\n",
      "\n",
      " [[ 69 214]]\n",
      "\n",
      " [[ 69 220]]\n",
      "\n",
      " [[ 70 221]]\n",
      "\n",
      " [[ 70 225]]\n",
      "\n",
      " [[ 71 226]]\n",
      "\n",
      " [[ 71 232]]\n",
      "\n",
      " [[ 72 233]]\n",
      "\n",
      " [[ 72 238]]\n",
      "\n",
      " [[ 73 239]]\n",
      "\n",
      " [[ 73 246]]\n",
      "\n",
      " [[ 74 247]]\n",
      "\n",
      " [[ 74 252]]\n",
      "\n",
      " [[ 75 253]]\n",
      "\n",
      " [[ 75 258]]\n",
      "\n",
      " [[ 76 259]]\n",
      "\n",
      " [[ 76 264]]\n",
      "\n",
      " [[ 77 265]]\n",
      "\n",
      " [[ 77 271]]\n",
      "\n",
      " [[ 78 272]]\n",
      "\n",
      " [[ 78 279]]\n",
      "\n",
      " [[ 79 280]]\n",
      "\n",
      " [[ 79 285]]\n",
      "\n",
      " [[ 80 286]]\n",
      "\n",
      " [[ 80 292]]\n",
      "\n",
      " [[ 81 293]]\n",
      "\n",
      " [[ 81 297]]\n",
      "\n",
      " [[ 82 298]]\n",
      "\n",
      " [[ 82 305]]\n",
      "\n",
      " [[ 83 306]]\n",
      "\n",
      " [[ 83 312]]\n",
      "\n",
      " [[ 84 313]]\n",
      "\n",
      " [[ 84 319]]\n",
      "\n",
      " [[ 85 320]]\n",
      "\n",
      " [[ 85 325]]\n",
      "\n",
      " [[ 86 326]]\n",
      "\n",
      " [[ 86 332]]\n",
      "\n",
      " [[ 87 333]]\n",
      "\n",
      " [[ 87 340]]\n",
      "\n",
      " [[ 88 341]]\n",
      "\n",
      " [[ 88 347]]\n",
      "\n",
      " [[ 89 348]]\n",
      "\n",
      " [[ 89 354]]\n",
      "\n",
      " [[ 90 355]]\n",
      "\n",
      " [[ 90 362]]\n",
      "\n",
      " [[ 91 363]]\n",
      "\n",
      " [[ 91 368]]\n",
      "\n",
      " [[ 92 369]]\n",
      "\n",
      " [[ 92 376]]\n",
      "\n",
      " [[ 93 377]]\n",
      "\n",
      " [[ 93 383]]\n",
      "\n",
      " [[ 94 384]]\n",
      "\n",
      " [[ 94 387]]\n",
      "\n",
      " [[ 97 390]]\n",
      "\n",
      " [[102 390]]\n",
      "\n",
      " [[103 389]]\n",
      "\n",
      " [[110 389]]\n",
      "\n",
      " [[111 388]]\n",
      "\n",
      " [[118 388]]\n",
      "\n",
      " [[119 387]]\n",
      "\n",
      " [[127 387]]\n",
      "\n",
      " [[128 386]]\n",
      "\n",
      " [[135 386]]\n",
      "\n",
      " [[136 385]]\n",
      "\n",
      " [[143 385]]\n",
      "\n",
      " [[144 384]]\n",
      "\n",
      " [[152 384]]\n",
      "\n",
      " [[153 383]]\n",
      "\n",
      " [[161 383]]\n",
      "\n",
      " [[162 382]]\n",
      "\n",
      " [[169 382]]\n",
      "\n",
      " [[170 381]]\n",
      "\n",
      " [[178 381]]\n",
      "\n",
      " [[179 380]]\n",
      "\n",
      " [[186 380]]\n",
      "\n",
      " [[187 379]]\n",
      "\n",
      " [[194 379]]\n",
      "\n",
      " [[195 378]]\n",
      "\n",
      " [[201 378]]\n",
      "\n",
      " [[202 377]]\n",
      "\n",
      " [[205 377]]\n",
      "\n",
      " [[207 375]]\n",
      "\n",
      " [[208 375]]\n",
      "\n",
      " [[210 373]]\n",
      "\n",
      " [[210 369]]\n",
      "\n",
      " [[209 368]]\n",
      "\n",
      " [[209 358]]\n",
      "\n",
      " [[208 357]]\n",
      "\n",
      " [[208 350]]\n",
      "\n",
      " [[207 349]]\n",
      "\n",
      " [[207 344]]\n",
      "\n",
      " [[206 343]]\n",
      "\n",
      " [[206 336]]\n",
      "\n",
      " [[205 335]]\n",
      "\n",
      " [[206 334]]\n",
      "\n",
      " [[205 333]]\n",
      "\n",
      " [[205 327]]\n",
      "\n",
      " [[204 326]]\n",
      "\n",
      " [[204 321]]\n",
      "\n",
      " [[203 320]]\n",
      "\n",
      " [[203 313]]\n",
      "\n",
      " [[202 312]]\n",
      "\n",
      " [[202 308]]\n",
      "\n",
      " [[201 307]]\n",
      "\n",
      " [[201 299]]\n",
      "\n",
      " [[200 298]]\n",
      "\n",
      " [[200 291]]\n",
      "\n",
      " [[199 290]]\n",
      "\n",
      " [[199 284]]\n",
      "\n",
      " [[198 283]]\n",
      "\n",
      " [[198 278]]\n",
      "\n",
      " [[197 277]]\n",
      "\n",
      " [[197 270]]\n",
      "\n",
      " [[196 269]]\n",
      "\n",
      " [[196 264]]\n",
      "\n",
      " [[195 263]]\n",
      "\n",
      " [[195 257]]\n",
      "\n",
      " [[194 256]]\n",
      "\n",
      " [[194 250]]\n",
      "\n",
      " [[193 249]]\n",
      "\n",
      " [[193 243]]\n",
      "\n",
      " [[192 242]]\n",
      "\n",
      " [[192 236]]\n",
      "\n",
      " [[191 235]]\n",
      "\n",
      " [[191 229]]\n",
      "\n",
      " [[190 228]]\n",
      "\n",
      " [[190 223]]\n",
      "\n",
      " [[189 222]]\n",
      "\n",
      " [[189 216]]\n",
      "\n",
      " [[188 215]]\n",
      "\n",
      " [[188 210]]\n",
      "\n",
      " [[187 209]]\n",
      "\n",
      " [[187 203]]\n",
      "\n",
      " [[183 199]]]\n",
      "[[[183 199]]\n",
      "\n",
      " [[ 69 214]]\n",
      "\n",
      " [[ 97 390]]\n",
      "\n",
      " [[210 373]]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/21 上午10:48\n",
    "# @Author  : play4fun\n",
    "# @File    : 图像相减2.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "图像相减2.py:\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# img1=cv2.imread('subtract1.jpg')\n",
    "img1 = cv2.imread('img/subtract1.jpg', 0)  # 灰度图\n",
    "# img2=cv2.imread('subtract2.jpg')\n",
    "# img2 = cv2.imread('subtract2.jpg', 0)\n",
    "img22 = cv2.imread('img/subtract2.jpg')\n",
    "img2 = cv2.cvtColor(img22, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# cv2.imshow('subtract1', img1)\n",
    "# cv2.imshow('subtract2', img2)\n",
    "\n",
    "#\n",
    "st = cv2.subtract(img2, img1)\n",
    "# st = cv2.subtract(img1, img2)#相反\n",
    "st[st <= 5] = 0  # 把小于20的像素点设为0\n",
    "\n",
    "# cv2.imshow('after subtract', st)\n",
    "\n",
    "'''\n",
    "# 直方图，看看大部分像素集中在哪个区域\n",
    "# plt.plot(st)\n",
    "pxs = st.ravel()\n",
    "pxs=[x for x in pxs if x>5]#20,10\n",
    "plt.hist(pxs, 256, [0, 256])\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# 效果好一点\n",
    "# ret,threshold=cv2.threshold(st,0, 127, cv2.THRESH_BINARY)\n",
    "ret, threshold = cv2.threshold(st, 50, 255, cv2.THRESH_BINARY)\n",
    "# cv2.imshow('after threshold', threshold)\n",
    "\n",
    "image, contours, hierarchy = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "areas = list()\n",
    "for i, cnt in enumerate(contours):\n",
    "\n",
    "    areas.append((i, cv2.contourArea(cnt)))\n",
    "\n",
    "#\n",
    "a2 = sorted(areas, key=lambda d: d[1], reverse=True)\n",
    "\n",
    "'''\n",
    "for i,are in a2:\n",
    "    if are <100:\n",
    "        continue\n",
    "    cv2.drawContours(img22, contours, i, (0, 0, 255), 3)\n",
    "    print(i,are)\n",
    "\n",
    "    cv2.imshow('drawContours',img22)\n",
    "    cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "# TODO 截取原图，把长方形纠正\n",
    "cnt = contours[0]\n",
    "print(cnt)\n",
    "hull = cv2.convexHull(cnt)\n",
    "epsilon = 0.001 * cv2.arcLength(hull, True)\n",
    "simplified_cnt = cv2.approxPolyDP(hull, epsilon, True)\n",
    "\n",
    "epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "print(approx)\n",
    "cv2.drawContours(img22, [approx], 0, (255, 0, 0), 3)\n",
    "cv2.imshow('approxPolyDP', img22)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n",
    "#exit(3)\n",
    "\n",
    "# findHomography(srcPoints, dstPoints, method=None, ransacReprojThreshold=None, mask=None, maxIters=None, confidence=None)\n",
    "# H = cv2.findHomography(srcPoints=cnt.astype('single'), dstPoints=np.array([[[0., 0.]], [[2150., 0.]], [[2150., 2800.]], [[0., 2800.]]]))\n",
    "# M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "\n",
    "# now that we have our screen contour, we need to determine\n",
    "# the top-left, top-right, bottom-right, and bottom-left\n",
    "# points so that we can later warp the image -- we'll start\n",
    "# by reshaping our contour to be our finals and initializing\n",
    "# our output rectangle in top-left, top-right, bottom-right,\n",
    "# and bottom-left order\n",
    "pts = approx.reshape(4, 2)\n",
    "rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "# the top-left point has the smallest sum whereas the\n",
    "# bottom-right has the largest sum\n",
    "s = pts.sum(axis=1)\n",
    "rect[0] = pts[np.argmin(s)]\n",
    "rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "# compute the difference between the points -- the top-right\n",
    "# will have the minumum difference and the bottom-left will\n",
    "# have the maximum difference\n",
    "diff = np.diff(pts, axis=1)\n",
    "rect[1] = pts[np.argmin(diff)]\n",
    "rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "# multiply the rectangle by the original ratio\n",
    "ratio = image.shape[0] / 300.0\n",
    "rect *= ratio\n",
    "\n",
    "\n",
    "# now that we have our rectangle of points, let's compute\n",
    "# the width of our new image\n",
    "(tl, tr, br, bl) = rect\n",
    "widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\n",
    "# ...and now for the height of our new image\n",
    "heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\n",
    "# take the maximum of the width and height values to reach\n",
    "# our final dimensions\n",
    "maxWidth = max(int(widthA), int(widthB))\n",
    "maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "# construct our destination points which will be used to\n",
    "# map the screen to a top-down, \"birds eye\" view\n",
    "dst = np.array([\n",
    "    [0, 0],\n",
    "    [maxWidth - 1, 0],\n",
    "    [maxWidth - 1, maxHeight - 1],\n",
    "    [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "# calculate the perspective transform matrix and warp\n",
    "# the perspective to grab the screen\n",
    "M = cv2.getPerspectiveTransform(rect, dst)\n",
    "warp = cv2.warpPerspective(img22, M, (maxWidth, maxHeight))\n",
    "\n",
    "# final_image = cv2.warpPerspective(img22, H, (2150, 2800))\n",
    "\n",
    "cv2.imshow('final_image', warp)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 学习图像上的算术运算 加法 减法 位运算等\n",
    "\n",
    "# 你可以使用函数 cv2.add() 将两幅图像进行加法运算 当然也可以直接使 用 numpy ，\n",
    "# res=img1+img\n",
    "# 两幅图像的大小 类型必须一致 ，或者第二个 图像可以使一个简单的标量值。\n",
    "\n",
    "\n",
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "print(cv2.add(x, y))  # 250+10 = 260 => 255\n",
    "# [[255]]\n",
    "print(x + y)  # 250+10=260%256=4\n",
    "# [4]\n",
    "\n",
    "\n",
    "# 图像混合\n",
    "img1 = cv2.imread('img/apple.jpg')\n",
    "img2 = cv2.imread('img/baboon.jpg')\n",
    "\n",
    "dst = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)  # 第一幅图的权重是 0.7 第二幅图的权重是 0.3\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 60 255 255]]]\n",
      "[[[0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# wrong\n",
    "# green=np.uint8([0,255,0])\n",
    "# print green\n",
    "# hsv_green=cv2.cvtColor(green,cv2.COLOR_BGR2HSV)\n",
    "# print hsv_green\n",
    "\n",
    "\n",
    "# scn (the number of channels of the source),\n",
    "# i.e. self.img.channels(), is neither 3 nor 4.\n",
    "#\n",
    "# depth (of the source),\n",
    "# i.e. self.img.depth(), is neither CV_8U nor CV_32F.\n",
    "# 所以不能用 [0,255,0] 而 用 [[[0,255,0]]]\n",
    "# 的三层括号应 分别对应于 cvArray cvMat IplImage\n",
    "\n",
    "\n",
    "green = np.uint8([[[0, 255, 0]]])\n",
    "hsv_green = cv2.cvtColor(green, cv2.COLOR_BGR2HSV)\n",
    "print(hsv_green)\n",
    "# [[[60 255 255]]]\n",
    "\n",
    "black = np.uint8([[[0, 0, 0]]])\n",
    "hsv_black = cv2.cvtColor(black, cv2.COLOR_BGR2HSV)\n",
    "print(hsv_black)\n",
    "# [[[0 0 0]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "物体跟踪\n",
    "\n",
    "• 从视频中获取每一帧图像\n",
    "• 将图像转换到 HSV 空间\n",
    "• 设置 HSV 阈值到蓝色范围。\n",
    "• 获取蓝色物体 当然我们 可以做其他任何我们想做的事 \n",
    "比如 在蓝色 物体周围画一个圈。\n",
    "\n",
    "\n",
    "当你学习了【轮廓】之后 你就会学到更多 相关知识\n",
    "那是你就可以找到物体的重心 并根据重心来跟踪物体\n",
    "仅仅在摄像头前挥挥手就可以画出同的图形，或者其他更有趣的事。\n",
    "'''\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret = cap.set(3, 640)\n",
    "ret = cap.set(4, 480)\n",
    "\n",
    "# 定蓝色的阈值\n",
    "# lower = np.array([110, 50, 50])\n",
    "# upper = np.array([130, 255, 255])\n",
    "\n",
    "#黄色-乒乓球\n",
    "lower = np.array([20, 100, 100])\n",
    "upper = np.array([30, 255, 255])\n",
    "\n",
    "# 黑色\n",
    "# lower_black = np.array([0, 0, 0])\n",
    "# upper_black = np.array([180, 255, 30])\n",
    "\n",
    "while True:\n",
    "    # 获取每一帧\n",
    "    ret, frame = cap.read()\n",
    "    # 换到 HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 根据阈值构建掩模\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    # mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "    # 对原图像和掩模位运算\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # 显示图像\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.moveWindow('frame', x=0, y=0)  # 原地\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.moveWindow('mask', x=frame.shape[1], y=0)#右边\n",
    "    cv2.imshow('res', res)\n",
    "    cv2.moveWindow('res', y=frame.shape[0], x=0)#下边\n",
    "\n",
    "    k = cv2.waitKey(1)  # & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "# 关闭窗口\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "扩展缩放\n",
    "\n",
    "在缩放时我们推荐使用 cv2.INTER_AREA\n",
    "在扩展时我们推荐使用 v2.INTER_CUBIC 慢) 和 v2.INTER_LINEAR。\n",
    "默认情况下所有改变图像尺寸大小的操作使用的插值方法 是 cv2.INTER_LINEAR。\n",
    "\n",
    "Resize(src, dst, interpolation=CV_INTER_LINEAR)\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/messi5.jpg')\n",
    "# 下面的 None 本应 是 出图像的尺寸 但是因为后边我们设置了缩放因子\n",
    "# 因此这里为 None\n",
    "res = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# OR\n",
    "# 我们直接设置输出图像的尺寸 所以不用设置缩放因子\n",
    "# height, width = img.shape[:2]\n",
    "# res = cv2.resize(img, (2 * width, 2 * height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow('resize', res)\n",
    "cv2.imshow('src img', img)\n",
    "\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/12 下午12:21\n",
    "# @Author  : play4fun\n",
    "# @File    : 平移.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "平移.py:平移就是将对 换一个位置。如果你 沿 (x, y) 方向移动\n",
    "移动的距离 是 (tx,ty)\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret = cap.set(3, 640)\n",
    "ret = cap.set(4, 480)\n",
    "while True:\n",
    "    # 获取每一帧\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #  换到 HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #  定蓝色的阈值\n",
    "    lower_blue = np.array([110, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    # 根据阈值构建掩模\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    # 对原图像和掩模 进行位运算\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # 显示图像\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('res', res)\n",
    "\n",
    "    k = cv2.waitKey(1)  # & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "# 关 窗口\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/12 下午12:31\n",
    "# @Author  : play4fun\n",
    "# @File    : 14.2平移-2.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "14.2平移-2.py:\n",
    "http://docs.opencv.org/3.2.0/da/d6e/tutorial_py_geometric_transformations.html\n",
    "函数 cv2.warpAffine() 的第三个参数的是 出图像的大小 ，它的格式 应 是图像的(宽,高) 。\n",
    "图像的宽对应的是列数, 高对应的是行数。\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/messi5.jpg', 0)\n",
    "rows, cols = img.shape\n",
    "\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow('img', dst)\n",
    "cv2.waitKey(10011)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 移动了100,50 个像素。\n",
    "img = cv2.imread('img/messi5.jpg', 0)\n",
    "rows, cols = img.shape\n",
    "\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow('img', dst)\n",
    "cv2.waitKey(11110)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "(451, 451, 3)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "仿射变换\n",
    "在仿射变换中 原图中所有的平行线在结果图像中同样平行。\n",
    "为了创建 这个矩阵，我们需要从原图像中找到三个点以及他们在 出图像中的位置。\n",
    "然后 cv2.getAffineTransform 会创建一个 2x3 的矩  最后 个矩 会 传给 函数 cv2.warpAffine。\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('drawing.png')\n",
    "rows, cols, ch = img.shape\n",
    "print(img.shape)\n",
    "\n",
    "pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2)\n",
    "dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# plt.subplot(121, plt.imshow(img), plt.title('Input'))\n",
    "# plt.subplot(122, plt.imshow(dst), plt.title('Output'))\n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=98)\n",
    "p1 = plt.subplot(211)\n",
    "p1.imshow(img)\n",
    "p1.set_title('Input')\n",
    "\n",
    "p2 = plt.subplot(212)\n",
    "p2.imshow(dst)\n",
    "p2.set_title('Output')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "透视变换\n",
    "对于透视变换 ，我们需要一个 3x3 变换矩 。\n",
    "在变换前后直线 是直线。\n",
    "构建 个变换矩  你需要在输入图像上找 4 个点， 以及他们在输出图 像上对应的位置。\n",
    "四个点中的任意三个都不能共线。这个变换矩阵可以用函数 cv2.getPerspectiveTransform() 构建。\n",
    "然后把这个矩阵传给函数 cv2.warpPerspective。\n",
    "\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/sudoku.jpg')\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[56, 65], [368, 52], [28, 387], [389, 390]])\n",
    "pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "dst = cv2.warpPerspective(img, M, (300, 300))\n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=98)\n",
    "p1 = plt.subplot(211)\n",
    "p1.imshow(img)\n",
    "p1.set_title('Input')\n",
    "\n",
    "p2 = plt.subplot(212)\n",
    "p2.imshow(dst)\n",
    "p2.set_title('Output')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 旋转\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/messi5.jpg', 0)\n",
    "rows, cols = img.shape\n",
    "\n",
    "# 的第一个参数为旋转中心 第二个为旋转角度\n",
    "#  第三个为旋转后的缩放因子\n",
    "# 可以通过设置旋转中心，缩放因子，以及窗口大小来防止旋转后超出边界的问题\n",
    "M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 45, 0.6)\n",
    "\n",
    "# 第三个参数是输出图像的尺寸中心\n",
    "dst = cv2.warpAffine(img, M, (2 * cols, 2 * rows))\n",
    "\n",
    "cv2.imshow('img', dst)\n",
    "\n",
    "cv2.waitKey(11110)  # & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "自适应阈值\n",
    "\n",
    "Adaptive Method- 指定 算阈值的方法。\n",
    "– cv2.ADPTIVE_THRESH_MEAN_C  值取自相邻区域的平均值\n",
    "– cv2.ADPTIVE_THRESH_GAUSSIAN_C  值取值相邻区域 的加权和 ，权重为一个高斯窗口\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# img = cv2.imread('dave.jpg', 0)\n",
    "img = cv2.imread('img/sudoku.jpg', 0)\n",
    "# 中值滤波\n",
    "img = cv2.medianBlur(img, 5)\n",
    "ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 11 为 Block size 邻域大小 用来计算阈值的区域大小 ,\n",
    "# 2 为 C值，常数， 阈值就等于的平均值或者加权平均值减去这个常数。\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "          'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "Otsu's 二值化\n",
    "\n",
    "在第一 分中我们提到  retVal 当我们使用 Otsu 二值化时会用到它。  么它到底是什么呢\n",
    "在使用全局 值时 我们就是 便给了一个数来做 值  我们怎么知  我们 取的 个数的好坏呢?\n",
    " 答案就是不停的尝 。\n",
    " 如果是一副双峰图像 ，简 单来 双峰图像是指图像直方图中存在两个峰 呢 ？\n",
    " 我们岂不是应 在两个峰 之 的峰  一个值作为阈值 。\n",
    "  就是 Otsu 二值化 做的。\n",
    "  简单来说，就是对一副双峰图像自动根据其直方图计算出一个阈值。\n",
    "  对于非双峰图像 这 种方法 得到的结果可能会不理想 。\n",
    "\n",
    " 这里 用到的函数 是 cv2.threshold() 但是  需要多传入一个参数  flag  cv2.THRESH_OTSU。\n",
    "  这时 把 值 为 0。然后算法会找到最 优阈值 ，这 个最优 值就是 回值 retVal。\n",
    "  如果不使用 Otsu 二值化 返回的retVal 值与 设定的 阈值相等。\n",
    "\n",
    "下 的例子中  输入图像是一副带有噪声的图像。\n",
    "第一种方法 我们 设127 为全局 阈值。\n",
    "第二种方法 我们直接使用 Otsu 二值化。\n",
    "第三种方法 我 们 先使用一个 5x5 的 高斯核 去噪  然后再使用 Otsu 二值化。\n",
    "看看噪音 去除对结果的影响有多大吧。\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('noisy2.png', 0)\n",
    "# global thresholding\n",
    "ret1, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "# 5,5 为 斯核的大小 0 为标准差\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "# 阀值一定为 0\n",
    "ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image', 'Histogram', 'Global Thresholding (v=127)',\n",
    "          'Original Noisy Image', 'Histogram', \"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image', 'Histogram', \"Otsu's Thresholding\"]\n",
    "# 使用了 pyplot 中画直方图的方法 plt.hist,\n",
    "# 注意的是它的参数是一维数组\n",
    "# 所以使用了 numpy ravel 方法 将多维数组 换成一维 也可以使用 flatten 方法\n",
    "# ndarray.flat 1-D iterator over an array.\n",
    "# ndarray.flatten 1-D array copy of the elements of an array in row-major order.\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i * 3 + 1), plt.imshow(images[i * 3], 'gray')\n",
    "    plt.title(titles[i * 3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3, 3, i * 3 + 2), plt.hist(images[i * 3].ravel(), 256)\n",
    "    plt.title(titles[i * 3 + 1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3, 3, i * 3 + 3), plt.imshow(images[i * 3 + 2], 'gray')\n",
    "    plt.title(titles[i * 3 + 2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "简单阈值\n",
    "像素值高于阈值时 我们给这个像素 赋予一个新值， 可能是白色 ，\n",
    " 否则我们给它赋予另外一种颜色， 或是黑色 。\n",
    " 这个函数就是 cv2.threshhold()。\n",
    " 这个函数的第一个参数就是原图像\n",
    " 原图像应 是灰度图。\n",
    " 第二个参数就是用来对像素值进行分类的阈值。\n",
    " 第三个参数 就是当像素值高于， 有时是小于  阈值时应该被赋予的新的像素值。\n",
    " OpenCV 提供了多种不同的阈值方法 ， 是由第四个参数来决定的。\n",
    "  些方法包括\n",
    "• cv2.THRESH_BINARY\n",
    "• cv2.THRESH_BINARY_INV • cv2.THRESH_TRUNC\n",
    "• cv2.THRESH_TOZERO\n",
    "• cv2.THRESH_TOZERO_INV\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('grey-gradient.jpg', 0)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/12 下午1:27\n",
    "# @Author  : play4fun\n",
    "# @File    : 15-How-OTSU-work.py\n",
    "# @Software: PyCharm\n",
    "%matplotlib\n",
    "\"\"\"\n",
    "15-How-OTSU-work.py:\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('noisy2.png', 0)\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "# find normalized_histogram, and its cumulative distribution function\n",
    "#  算归一化直方图\n",
    "# CalcHist(image, accumulate=0, mask=NULL)\n",
    "\n",
    "hist = cv2.calcHist([blur], [0], None, [256], [0, 256])\n",
    "hist_norm = hist.ravel() / hist.max()\n",
    "Q = hist_norm.cumsum()\n",
    "\n",
    "bins = np.arange(256)\n",
    "fn_min = np.inf\n",
    "thresh = -1\n",
    "\n",
    "for i in range(1, 256):\n",
    "    p1, p2 = np.hsplit(hist_norm, [i])  # probabilities\n",
    "    q1, q2 = Q[i], Q[255] - Q[i]  # cum sum of classes\n",
    "    b1, b2 = np.hsplit(bins, [i])  # weights\n",
    "\n",
    "    # finding means and variances\n",
    "    m1, m2 = np.sum(p1 * b1) / q1, np.sum(p2 * b2) / q2\n",
    "    v1, v2 = np.sum(((b1 - m1) ** 2) * p1) / q1, np.sum(((b2 - m2) ** 2) * p2) / q2\n",
    "\n",
    "    # calculates the minimization function\n",
    "    fn = v1 * q1 + v2 * q2\n",
    "    if fn < fn_min:\n",
    "        fn_min = fn\n",
    "        thresh = i\n",
    "\n",
    "# find otsu's threshold value with OpenCV function\n",
    "ret, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "print(thresh, ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib\n",
    "'''\n",
    "2D 卷积\n",
    "OpenCV 提供的函数 cv.filter2D() 可以 我们对一幅图像  卷积操\n",
    "作。\n",
    "操作如下 将核放在图像的一个像素 A 上 求与核对应的图像上 25 5x5  个像素的和 在取平均数 用 个平均数替代像素 A 的值。 复以上操作直到 将图像的每一个像素值 更新一 。\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/opencv_logo.png')\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "# cv.Filter2D(src, dst, kernel, anchor=(-1, -1))\n",
    "# ddepth –desired depth of the destination image;\n",
    "# if it is negative, it will be the same as src.depth();\n",
    "# the following combinations of src.depth() and ddepth are supported:\n",
    "# src.depth() = CV_8U, ddepth = -1/CV_16S/CV_32F/CV_64F\n",
    "# src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F\n",
    "# src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F\n",
    "# src.depth() = CV_64F, ddepth = -1/CV_64F\n",
    "# when ddepth=-1, the output image will have the same depth as the source.\n",
    "\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(dst), plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/12 下午1:35\n",
    "# @Author  : play4fun\n",
    "# @File    : 图像模糊-平均.py\n",
    "# @Software: PyCharm\n",
    "%matplotlib\n",
    "\"\"\"\n",
    "图像模糊-平均.py:\n",
    " 是由一个归一化卷积框完成的。他只是用卷积框 盖区域所有像素的平 均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完  个任务。\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../data/opencv_logo.png')\n",
    "# blur = cv2.blur(img, (5, 5))\n",
    "\n",
    "'''\n",
    "现在把卷积核换成 斯核 简单来  方框不变 将原来每个方框的值是 相等的 现在  的值是符合 斯分布的 方框中心的值最大 其余方框根据  离中心元素的 离 减 构成一个 斯小山包。原来的求平均数现在变成求 加权平均数 全就是方框 的值 。\n",
    "'''\n",
    "# 0 是指根据窗口大小 (5,5) 来计算高斯函数标准差\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)  # 高斯模糊\n",
    "\n",
    "'''\n",
    " 名思义就是用与卷积框对应像素的中值来替代中心像素的值。 个滤波 器经常用来去 椒盐噪声。前 的滤波器 是用 算得到的一个新值来取代中 心像素的值 而中值滤波是用中心像素周围 也可以使他本  的值来取代他。 他能有效的去 噪声。卷积核的大小也应 是一个奇数。\n",
    "'''\n",
    "median = cv2.medianBlur(img, 5)  # 中值模糊\n",
    "\n",
    "'''\n",
    "函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去 噪  。\n",
    "但是 种操作与其他滤波器相比会比 慢。\n",
    "我们已经知 高斯滤波器是求 中心点 邻近区域像素的高斯加权平均值。\n",
    " 种 斯滤波器只考虑像素之间的空间关系 \n",
    " 而不会考虑像素值之间的关系 ，像素的相似度 。\n",
    " 所以 种方法不会考 虑 一个像素是否位于边界。\n",
    " 因此边界也会被模糊掉 而 这正不是我们想要。\n",
    "\n",
    "双边滤波在同时使用空 高斯权重和灰度值相似性 斯权 。\n",
    "空 高斯函数确保只有邻近区域的像素对中心点有影响\n",
    " 灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。\n",
    " 所以 种方法会确保边界不会被模糊掉\n",
    "  因为边界处的灰度值变化比较大。\n",
    "'''\n",
    "\n",
    "#16.4 双边滤波\n",
    "# cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)\n",
    "# d – Diameter of each pixel neighborhood that is used during filtering. # If it is non-positive, it is computed from sigmaSpace\n",
    "# 9  域直径 两个 75 分别是空  斯函数标准差 灰度值相似性 斯函数标准差\n",
    "# blur = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(blur), plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('j.png', 0)\n",
    "cv2.imshow('j.png', img)\n",
    "print(img.shape)\n",
    "\n",
    "#您可以将内核看作是一个小矩阵，我们在图像上滑动以进行（卷积）操作，例如模糊，锐化，边缘检测或其他图像处理操作。\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# 开运算：先腐蚀再膨胀就叫做开运算。就像我们上 介绍的 样， 它 用来，去噪声。\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.moveWindow('opening', x=img.shape[1], y=0)\n",
    "\n",
    "# 闭运算\n",
    "# 先膨胀再腐 。它经常 用来填充前景物体中的小洞 或者前景物体上的小黑点。\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('closing', closing)\n",
    "cv2.moveWindow('closing', x=img.shape[1] * 2, y=0)\n",
    "\n",
    "# 形态学梯度\n",
    "# 其实就是一幅图像膨胀与腐 的差别。\n",
    "# 结果看上去就像前景物体的 廓。\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "cv2.imshow('gradient', gradient)\n",
    "cv2.moveWindow('gradient', x=img.shape[1] * 3, y=0)\n",
    "\n",
    "# 礼帽\n",
    "# 原始图像与  开运算之后得到的图像的差。\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imshow('tophat', tophat)\n",
    "cv2.moveWindow('tophat', x=img.shape[1] * 4, y=0)\n",
    "\n",
    "# 黑帽  进行闭运算之后得到的图像与原始图像的差\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imshow('blackhat', blackhat)\n",
    "cv2.moveWindow('blackhat', x=img.shape[1] * 5, y=0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''\n",
    "结构化元素\n",
    "在前 的例子中我们使用 Numpy 构建了结构化元素 它是正方形的。\n",
    "但 有时我们 需要 构建一个椭圆形/圆形的核。\n",
    "为了实现 这种需求 ，提供了 OpenCV 函数 cv2.getStructuringElement()。\n",
    "你只  告诉 他 你需要的核的形状和大小。\n",
    "# Rectangular Kernel\n",
    ">>> cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "array([[1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1]], dtype=uint8)\n",
    "# Elliptical Kernel\n",
    ">>> cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)\n",
    "# Cross-shaped Kernel\n",
    ">>> cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/12 下午2:23\n",
    "# @Author  : play4fun\n",
    "# @File    : 一个重要的事.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "一个重要的事.py:\n",
    "当我们可以  参 数 -1 来 定 出图像的深度 数据类型 与原图像保持一致\n",
    "但是我们在代 码中使用的却是 cv2.CV_64F。 是为什么呢 ？\n",
    "想象一下一个从黑到白的边界的导数是整数，而一个从白到黑的边界点导数却是负数。\n",
    "如果原图像的深度是 np.int8 时 所有的负值 会 截断变成 0\n",
    " 换句话就是把边界丢失掉。\n",
    "所以如果 两种边界你 想检测到\n",
    "最好的的办法就是将输出的数据类型 设置的更高\n",
    "  比如 cv2.CV_16S cv2.CV_64F 等。\n",
    "  取绝对值然后再把它 回 到 cv2.CV_8U。\n",
    "  下 的示例演示了输出图片的深度不同造成的不同效果。\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../data/box.jpg', 0)\n",
    "\n",
    "# Output dtype = cv2.CV_8U\n",
    "sobelx8u = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=5)\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx64f = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "abs_sobel64f = np.absolute(sobelx64f)\n",
    "sobel_8u = np.uint8(abs_sobel64f)\n",
    "\n",
    "plt.subplot(1, 3, 1), plt.imshow(img, cmap='gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1, 3, 2), plt.imshow(sobelx8u, cmap='gray')\n",
    "plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1, 3, 3), plt.imshow(sobel_8u, cmap='gray')\n",
    "plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "原理\n",
    "梯度简单来说就是求导。\n",
    "OpenCV 提供了三种不同的梯度滤波器 或者说是高通滤波器：Sobel，  Scharr 和 Laplacian。我们会意义介绍他们。\n",
    "Sobel Scharr 其实就是求一阶或二阶导数。\n",
    "Scharr 是对 Sobel (使用小的卷积核求解 梯度角度时 )的优化。\n",
    "Laplacian 是求二阶导数。\n",
    "\n",
    "\n",
    "Sobel 算子是高斯平滑与微分操作的结合体 所以它的抗噪声能力很好。\n",
    " 你可以设定求导的方向 xorder 或 yorder 。\n",
    " 可以设定使用的卷积核的大 小 ksize 。\n",
    " 如果 ksize=-1 会使用 3x3 的 Scharr 滤波器\n",
    " 它的的效果  比 3x3 的 Sobel 滤波器好 而且 度相同 所以在使用 3x3 滤波器时应 尽 量 使用 Scharr 滤波器 。\n",
    "\n",
    "Laplacian 算子\n",
    "拉普拉斯算子可以使用二阶导数的形式定义 ，可假设其离散实现类似于二阶Sobel 导数\n",
    "事实上 OpenCV 在 算拉普拉斯算子时直接 用 Sobel 算 子\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../data/sudoku.jpg', 0)\n",
    "# cv2.CV_64F 出图像的深度 数据类型 可以使用 -1, 与原图像保持一致 np.uint8\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "# 参数 1,0 为只在 x 方向求一 导数 最大可以求 2 导数。\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "# 参数 0,1 为只在 y 方向求一 导数 最大可以求 2 导数。\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "plt.subplot(2, 2, 1), plt.imshow(img, cmap='gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(2, 2, 2), plt.imshow(laplacian, cmap='gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(2, 2, 3), plt.imshow(sobelx, cmap='gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(2, 2, 4), plt.imshow(sobely, cmap='gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "Canny 边缘检测是一种 常流 的 缘检测算法 是 John F.Canny 在\n",
    "1986 年提出的。它是一个有很多步构成的算法\n",
    "由于 缘检测很容易受到噪声影响 所以第一步是使用 5x5 的 斯滤波器 去 噪声\n",
    "对平滑后的图像使用 Sobel 算子 算水平方向和竖直方向的一 导数 图 像梯度  Gx 和 Gy\n",
    "梯度的方向一般总是与边界垂直。\n",
    "梯度方向 归为四类： 垂直 水平 和 两个对角线。\n",
    "非极大值抑制\n",
    "\n",
    "滞后阈值\n",
    "现在 确定 些 界才是真正的边界。 时我们   置两个阈值  minVal 和 maxVal。\n",
    "当图像的灰度梯度 于 maxVal 时  为是真的边界\n",
    "那些低于 minVal 的 界会 抛弃。\n",
    "如果介于两者之间的  就 看这个点是否与某个被确定为真正的边界点相连\n",
    "如果是就认为它也是边界点 如果不是 就抛弃。\n",
    "\n",
    "OpenCV 中的 Canny 边界检测\n",
    "在 OpenCV 中只 需要 一个函数 cv2.Canny() 就可以完成以上几步。\n",
    "  我们看如何使用这个函数。\n",
    "第一个参数是输入图像。\n",
    "第二和第三 个分别是 minVal 和 maxVal。\n",
    "第三个参数 置用来计算图像梯度的 Sobel卷积核的大小  默认值为 3。\n",
    "最后一个参数是 L2gradient 它可以用来 设定 求梯度大小的方程。\n",
    "如果 为 True 就会使用我们上 提到 的方程 否则 使用方程 Edge−Gradient (G) = |G2x| + |G2y| 代替，  默认值为 False。\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../data/messi5.jpg',0)\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow('Edges',edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# plt.subplot(121), plt.imshow(img, cmap='gray')\n",
    "# plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
    "# plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
