{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:12\n",
    "# @Author  : play4fun\n",
    "# @File    : 41.2-BackgroundSubtractorMOG.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "41.2-BackgroundSubtractorMOG.py:\n",
    "在很多基础应用中背景检出 是一个 常  的步 。例如 客统  使 用一个 态摄像头来 录 入和离开房 的人数 或者是交 摄像头   提 取交 工具的信息等。\n",
    "在所有的 些例子中  先 将人或 单独提取出来。 技术上来  我们  从 止的背景中提取移动的前景。\n",
    "\n",
    "但是我们现在讲的背景建模是基于时间序列的\n",
    " 因此每一个像素点所在的位置在整个时间序列中 就会有很多值 从而构成一个分布。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('img/vtest.avi')\n",
    "#cap = cv2.VideoCapture(0)#笔记本摄像头\n",
    "\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "# 可选参数 比如 进行建模场景的时间长度 高斯混合成分的数量-阈值等\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # frame = cv2.flip(frame, flipCode=1)  # 左右翻转\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    cv2.imshow('frame', fgmask)\n",
    "    cv2.waitKey(10000) #& 0xff\n",
    "#     if k == ord('q'):\n",
    "#         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:16\n",
    "# @Author  : play4fun\n",
    "# @File    : 41.3-BackgroundSubtractorMOG2.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "41.3-BackgroundSubtractorMOG2.py:\n",
    "这个算法的一个特点是它为每一个像素选择一个合适数目的 斯分布。\n",
    "上一个方法中我们使用是 K 给斯分 布 。\n",
    " 这样就会对由于亮度等发生变化引起的场景变化产生更好的适应。\n",
    "和前面一样我们  创建一个背景对 。但在  我们我们可以 择是否 检测阴影。如果 detectShadows = True 默认值\n",
    "它就会检测并将影子标记出来 但是 样做会降低处理速度。影子会 标记为灰色。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('img/vtest.avi')\n",
    "#cap = cv2.VideoCapture(0)#笔记本摄像头\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # frame = cv2.flip(frame, flipCode=1)  # 左右翻转\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    cv2.imshow('frame', fgmask)\n",
    "    cv2.waitKey(10030) #& 0xff\n",
    "#     if k == ord('q'):\n",
    "#         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:18\n",
    "# @Author  : play4fun\n",
    "# @File    : 41.4-BackgroundSubtractorGMG.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "41.4-BackgroundSubtractorGMG.py:\n",
    "\n",
    "它使用前 很少的图像   为前 120 帧   背景建模。使用了概率前 景估 算法 使用 叶斯估  定前景 。 是一种自 应的估  新 察到的 对 比旧的对 具有更 的权\n",
    "从而对光照变化产生 应。一些形态学操作 如开 算  算等 用来 去不  的噪 。在前几帧图像中你会得到一个  色窗口。\n",
    "  对结果  形态学开 算对与去 噪声很有帮助。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('img/vtest.avi')\n",
    "#cap = cv2.VideoCapture(0)#笔记本摄像头\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "counter=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('frame', fgmask)#前 120 帧\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "\n",
    "    cv2.waitKey(10000)  # & 0xff\n",
    "#     if k == ord('q'):\n",
    "#         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:18\n",
    "# @Author  : play4fun\n",
    "# @File    : 41.4-BackgroundSubtractorGMG.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "41.4-BackgroundSubtractorGMG.py:\n",
    "\n",
    "它使用前 很少的图像   为前 120 帧   背景建模。使用了概率前 景估 算法 使用 叶斯估  定前景 。 是一种自 应的估  新 察到的 对 比旧的对 具有更 的权  从而对光照变化产生 应。一些形态学操作 如开 算  算等 用来 去不  的噪 。在前几帧图像中你会得到一个  色窗口。\n",
    "  对结果  形态学开 算对与去 噪声很有帮助。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture('../data/vtest.avi')\n",
    "cap = cv2.VideoCapture(0)#笔记本摄像头\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "counter=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('frame', fgmask)#前 120 帧\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "\n",
    "    k = cv2.waitKey(1)  # & 0xff\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/11/14 17:09\n",
    "# @Author  : play4fun\n",
    "# @File    : cc1.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "camera_calibration1.py:\n",
    "参考：http://blog.csdn.net/dcrmg/article/details/52939318\n",
    "\n",
    "有结果，但是摄像头分辨率太高，程序运行太慢了\n",
    "\n",
    "所用棋盘来自\n",
    "http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration?action=AttachFile&do=view&target=check-108.pdf\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "#等比缩放\n",
    "frame_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)#4 ，720\n",
    "frame_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)#3   ，1280\n",
    "frame_height=int(480/frame_width*frame_height)#270\n",
    "ret = cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)#高\n",
    "ret = cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "#\n",
    "\n",
    "while cap.isOpened():\n",
    "    # img = cv2.imread(fname)\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(image=gray, patternSize=(6, 4), corners=None)\n",
    "    '''\n",
    "    第一个参数Image，传入拍摄的棋盘图Mat图像，必须是8位的灰度或者彩色图像；\n",
    "第二个参数patternSize，每个棋盘图上内角点的行列数，一般情况下，行列数不要相同，便于后续标定程序识别标定板的方向；\n",
    "第三个参数corners，用于存储检测到的内角点图像坐标位置，一般用元素是Point2f的向量来表示：vector<Point2f> image_points_buf;\n",
    "第四个参数flage：用于定义棋盘图上内角点查找的不同处理方式，有默认值。\n",
    "    '''\n",
    "    print(corners)\n",
    "    print('---------')\n",
    "    if ret == True:\n",
    "        # objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        # imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (6, 4), corners2, ret)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "    key = cv2.waitKey(delay=10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:29\n",
    "# @Author  : play4fun\n",
    "# @File    : 其他.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "其他.py:\n",
    "\"\"\"\n",
    "import cv2\n",
    "\n",
    "# 标定\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# 畸变校正\n",
    "img = cv2.imread('left12.jpg')\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "# 使用 cv2.undistort()  是最简单的方法。只 使用这个函数和上面得到 的 ROI 对结果进行裁剪。\n",
    "\n",
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y + h, x:x + w]\n",
    "cv2.imwrite('calibresult.png', dst)\n",
    "\n",
    "# 使用 remapping  应 属于 曲线救国 了。 先我们 找到从畸变图像到畸变图像的映射方程。再使用 重映射方程\n",
    "# undistort\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "dst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y + h, x:x + w]\n",
    "cv2.imwrite('calibresult.png', dst)\n",
    "# 你会发现结果图像中所有的边界 变直了\n",
    "\n",
    "# 反向投影误差\n",
    "# 我们可以利用反向投影 差对我们找到的参数的准确性  估 。\n",
    "# 得到的 结果越接近 0 越好。有了内部参数 畸变参数和旋 变换矩  我们就可以使 用 cv2.projectPoints() 将对象点转换到图像点。\n",
    "# 然后就可以 算变换得到 图像与角点检测算法的绝对差了。\n",
    "# 然后我们计算所有标定图像的误差平均值。\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "    mean_error += error\n",
    "print(\"total error: \", mean_error / len(objpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:44\n",
    "# @Author  : play4fun\n",
    "# @File    : calib3d.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "calib3d.py:\n",
    "在图像中绘制一些 2D 的线条来产生 3D 的效果\n",
    "\n",
    "在棋盘的第一个角点绘制 3D 坐标  X Y Z\n",
    " X  为蓝色 Y  为绿色 Z  为红色。\n",
    " 在视觉效果上来看 Z 轴应 是垂直于棋盘平面的。\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load previously saved data摄像机矩阵和畸变系数\n",
    "with np.load('B.npz') as X:\n",
    "    mtx, dist, _, _ = [X[i] for i in ('mtx', 'dist', 'rvecs', 'tvecs')]\n",
    "\n",
    "\n",
    "# 函数 draw 它的参数有棋盘上的角点\n",
    "#  使用 cv2.findChessboardCorners() 得到\n",
    "#  绘制的 3D 坐标轴上的点\n",
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255, 0, 0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0, 255, 0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0, 0, 255), 5)\n",
    "    return img\n",
    "\n",
    "\n",
    "# 渲染一个立方体\n",
    "def draw_cube(img, corners, imgpts):\n",
    "    imgpts = np.int32(imgpts).reshape(-1, 2)\n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]], -1, (0, 255, 0), -3)\n",
    "    # draw pillars in blue color\n",
    "    for i, j in zip(range(4), range(4, 8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]), (255), 3)\n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]], -1, (0, 0, 255), 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "# 设置终止条件 对象点 棋盘上的 3D 角点 和坐标轴点\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((6 * 7, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "axis = np.float32([[3, 0, 0], [0, 3, 0], [0, 0, -3]]).reshape(-1, 3)\n",
    "# 渲染一个立方体\n",
    "# axis = np.float32([[0, 0, 0], [0, 3, 0], [3, 3, 0], [3, 0, 0],\n",
    "#                    [0, 0, -3], [0, 3, -3], [3, 3, -3], [3, 0, -3]])\n",
    "\n",
    "'''\n",
    "很 常一样我们  加 图像。搜寻 7x6 的格子 如果发现 我们就把它 优化到亚像素级。然后使用函数:cv2.solvePnPRansac() 来 算旋 和变 换。但我们有了变换矩 之后 我们就可以利用它们将 些坐标 点映射到图 像平 中去。简单来  我们在图像平 上找到了与 3D 空 中的点 3,0,0  ,(0,3,0),(0,0,3) 相对应的点。然后我们就可以使用我们的函数 draw() 从图像 上的第一个 点开始绘制 接 些点的直线了。搞定   \n",
    "'''\n",
    "for fname in glob.glob('../data/left*.jpg'):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7, 6), None)\n",
    "    if ret == True:\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        # Find the rotation and translation vectors.\n",
    "        ret, rvecs, tvecs, inliers = cv2.solvePnP(objp, corners2, mtx, dist)\n",
    "        # project 3D points to image plane\n",
    "        imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "        img = draw(img, corners2, imgpts)\n",
    "        cv2.imshow('img', img)\n",
    "        k = cv2.waitKey(0) & 0xFF\n",
    "        if k == ord('s'):\n",
    "            cv2.imwrite(fname[:6] + '.png', img)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#如果你对计算机图形学感兴趣的  为了增加图像的真实性 你可以使用 OpenGL 来渲染更复杂的图形。 下一个目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午6:57\n",
    "# @Author  : play4fun\n",
    "# @File    : code.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "code.py:多视角几何基础，极点 极线 对极约束 对极平面\n",
    "\n",
    "在我们使用针孔相机时 我们会丢失大量重要的信息\n",
    " 比如 图像的深度  或者 图像上的点和摄像机的距离\n",
    "因为这是一个从 3D 到 2D 的转换。\n",
    "重要的问题：\n",
    " 使用这样的摄像机我们能否计算出深度信息呢？\n",
    "  答案 就是使用多个相机。\n",
    "  我们的眼睛就是这样工作的 使用两个摄像机 两个眼睛\n",
    "称为立体视角\n",
    "\n",
    "三角测量\n",
    "\n",
    "本征矩阵 E 和基础矩阵 F\n",
    "\n",
    "点越多越好 可以使用 RANSAC 算法得到更加稳定的结果\n",
    "\n",
    "使用 SIFT 描述符 FLANN 匹配器和比值检测\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# 找到极线\n",
    "def drawlines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r, c = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2] / r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 1)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "\n",
    "img1 = cv2.imread('myleft.jpg', 0)  # queryimage # left image\n",
    "img2 = cv2.imread('myright.jpg', 0)  # trainimage # right image\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)#TODO\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "good = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "# ratio test as per Lowe's paper\n",
    "for i, (m, n) in enumerate(matches):\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        good.append(m)\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "        pts1.append(kp1[m.queryIdx].pt)\n",
    "        # 匹配点列表，用它来计算【基础矩阵】\n",
    "        pts1 = np.int32(pts1)\n",
    "        pts2 = np.int32(pts2)\n",
    "        F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n",
    "        # We select only inlier points\n",
    "        pts1 = pts1[mask.ravel() == 1]\n",
    "        pts2 = pts2[mask.ravel() == 1]\n",
    "        # 从两幅图像中计算并绘制极线\n",
    "        # Find epilines corresponding to points in right image (second image) and\n",
    "        # drawing its lines on left image\n",
    "        lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "        lines1 = lines1.reshape(-1, 3)\n",
    "        img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "        # Find epilines corresponding to points in left image (first image) and\n",
    "        # drawing its lines on right image\n",
    "        lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "        lines2 = lines2.reshape(-1, 3)\n",
    "        img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "        plt.subplot(121), plt.imshow(img5)\n",
    "        plt.subplot(122), plt.imshow(img3)\n",
    "        plt.show()\n",
    "\n",
    "#从上图可以看出所有的极线都汇聚以图像外的一点  这个点就是极点。\n",
    "# 为了得到更好的结果 我们应 使用分辨率比较高的图像和 non-planar 点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午7:09\n",
    "# @Author  : play4fun\n",
    "# @File    : code.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "code.py:\n",
    "下图左侧为原始图像 右侧为深度图像。\n",
    "如图所示 结果中有很大的噪音。\n",
    "通过调整 numDisparities 和 blockSize 的值 我们会得到更好的结果。\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgL = cv2.imread('tsukuba_l.png', 0)\n",
    "imgR = cv2.imread('tsukuba_r.png', 0)\n",
    "\n",
    "#参数不对？\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "# stereo = cv2.StereoBM_create(numDisparities=16, blockSize=21)\n",
    "disparity = stereo.compute(imgL, imgR)\n",
    "\n",
    "#不行\n",
    "plt.imshow(disparity, 'gray')\n",
    "plt.show()\n",
    "\n",
    "# cv2.imshow('disparity',disparity)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
