{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50 into shape (64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fced34c53975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#trainData = np.float32(hogdata).reshape(-1, 64)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhogdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mresponses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 50 into shape (64)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午8:23\n",
    "# @Author  : play4fun\n",
    "# @File    : 47.2-使用SVM进行-手写数据OCR.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "47.2-使用SVM进行-手写数据OCR.py:\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "SZ = 20\n",
    "bin_n = 16  # Number of bins\n",
    "affine_flags = cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR\n",
    "\n",
    "\n",
    "# 使用方向梯度直方图Histogram of Oriented Gradients  HOG 作为特征向量\n",
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5 * SZ * skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (SZ, SZ), flags=affine_flags)\n",
    "    return img\n",
    "\n",
    "\n",
    "# 计算图像 X 方向和 Y 方向的 Sobel 导数\n",
    "def hog(img):\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "    bins = np.int32(bin_n * ang / (2 * np.pi))  # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10, :10], bins[10:, :10], bins[:10, 10:], bins[10:, 10:]\n",
    "    mag_cells = mag[:10, :10], mag[10:, :10], mag[:10, 10:], mag[10:, 10:]\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists)  # hist is a 64 bit vector\n",
    "    return hist\n",
    "\n",
    "\n",
    "# 最后 和前 一样 我们将大图分割成小图。使用每个数字的前 250 个作 为训练数据\n",
    "#  后 250 个作为测试数据\n",
    "img = cv2.imread('img/digits.png', 0)\n",
    "\n",
    "cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]\n",
    "# First half is trainData, remaining is testData\n",
    "train_cells = [i[:50] for i in cells]\n",
    "test_cells = [i[50:] for i in cells]\n",
    "\n",
    "deskewed = [map(deskew, row) for row in train_cells]\n",
    "# deskewed = [deskew(row) for row in train_cells]\n",
    "# deskewed = map(deskew, train_cells)\n",
    "hogdata = [map(hog, row) for row in deskewed]\n",
    "# hogdata = [hog(row) for row in deskewed]\n",
    "# hogdata = map(hog, deskewed)\n",
    "\n",
    "#trainData = np.float32(hogdata).reshape(-1, 64)\n",
    "trainData = np.array(hogdata).reshape(-1, 64)\n",
    "responses = np.float32(np.repeat(np.arange(10), 250)[:, np.newaxis])\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setC(2.67)\n",
    "svm.setGamma(5.383)\n",
    "svm.train(trainData, cv2.ml.ROW_SAMPLE, responses)\n",
    "svm.save('svm_data.dat')\n",
    "\n",
    "deskewed = [map(deskew, row) for row in test_cells]\n",
    "hogdata = [map(hog, row) for row in deskewed]\n",
    "testData = np.float32(hogdata).reshape(-1, bin_n * 4)\n",
    "\n",
    "result = svm.predict(testData)\n",
    "mask = result == responses\n",
    "correct = np.count_nonzero(mask)\n",
    "print(correct * 100.0 / result.size)\n",
    "# 94%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/2/24 下午3:00\n",
    "# @Author  : play4fun\n",
    "# @File    : 48.2.2_仅有一个特征的数据.py\n",
    "# @Software: PyCharm\n",
    "%matplotlib\n",
    "\"\"\"\n",
    "48.2.2_仅有一个特征的数据.py:\n",
    "\n",
    "输入参数\n",
    "1. samples: 应 是 np.float32 类型的数据 每个特征应 放在一列。\n",
    "2. nclusters(K): 聚类的最终数目。\n",
    "3. criteria: 终止 代的条件。当条件满 时 算法的 代终止。它应 是 一个含有 3 个成员的元组 它们是 typw max_iter epsilon\n",
    "4. attempts: 使用不同的 始标 来执 算法的次数。算法会 回紧密度 最好的标 。紧密度也会作为 出  回。\n",
    "5. flags 用来 置如何 择 始 心。 常我们有两个 择 cv2.KMEANS_PP_CENTERS 和 cv2.KMEANS_RANDOM_CENTERS。\n",
    "\n",
    "输出参数\n",
    "1. compactness 紧密度  回每个点到相应 心的 离的平方和。\n",
    "2. labels 标志数组 与上一节提到的代码相同  每个成员 标 为 0 1 等\n",
    "3. centers 由聚类的中心组成的数组\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 假 我们有一组数据 每个数据只有一个特征 1 维 。例如前 的 T 恤    我们只使用人们的  来决定 T 恤的大小。\n",
    "# 我们先来产生一些 机数据 并使用 Matplotlib 将它们绘制出来。\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.random.randint(25, 100, 25)\n",
    "y = np.random.randint(175, 255, 25)\n",
    "z = np.hstack((x, y))\n",
    "z = z.reshape((50, 1))\n",
    "z = np.float32(z)\n",
    "plt.hist(z, 256, [0, 256]), plt.show()\n",
    "# 现在我们有一个 度为 50 取值范围为 0 到 255 的向量z。我已经将向量z  重排 将它变成了一个列向量。\n",
    "# 当每个数据含有多个特征是 会很有用。然后我们数据类型 换成 np.float32。\n",
    "\n",
    "# exit(0)\n",
    "\n",
    "##\n",
    "\n",
    "# 现在我们使用KMeans函数。在之前我们应先置好终止条件。我的终止条件是算法执10次代或者精确度epsilon=1.0。\n",
    "\n",
    "# Define criteria = ( type, max_iter = 10 , epsilon = 1.0 )\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "# Set flags (Just to avoid line break in the code)\n",
    "\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "# Apply KMeans\n",
    "compactness, labels, centers = cv2.kmeans(z, 2, None, criteria, 10, flags)\n",
    "\n",
    "\n",
    "# 返回值有紧密度compactness,标志和中心。在本例中我的到的中心是60和207。标志的数目与测数据的多少是相同的每个数据会标上01等。取决与它们的中心是什么。\n",
    "\n",
    "A = z[labels == 0]\n",
    "B = z[labels == 1]\n",
    "\n",
    "# 现在我们可以根据它们的标志将把数据分两组。\n",
    "# 现在将A组数用红色示\n",
    "# 将B组数据用蓝色示,重心用黄色示。\n",
    "# Now plot 'A' in red, 'B' in blue, 'centers' in yellow\n",
    "plt.hist(A, 256, [0, 256], color='r')\n",
    "plt.hist(B, 256, [0, 256], color='b')\n",
    "plt.hist(centers, 32, [0, 256], color='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午9:01\n",
    "# @Author  : play4fun\n",
    "# @File    : 48.2.2-含有多个特征的数据.py\n",
    "# @Software: PyCharm\n",
    "%matplotlib\n",
    "\"\"\"\n",
    "48.2.2-含有多个特征的数据.py:\n",
    "身高\n",
    "体重\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 在前 的 T 恤例子中我们只考 了   现在我们也把体 考  去 也 就是两个特征。\n",
    "# 在前一节我们的数据是一个单列向 。每一个特征 排列成一列 每一  对应一个测 样本。\n",
    "# 在本例中我们的测 数据 应 50x2 的向  其中包含 50 个人的  和 体 。第一列对应与   第二列对应与体 。第一 包含两个元素 第一个 是第一个人的   \n",
    "#第二个是第一个人的体 。剩下的 对应与其他人的   和体 。\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = np.random.randint(25, 50, (25, 2))\n",
    "Y = np.random.randint(60, 85, (25, 2))\n",
    "Z = np.vstack((X, Y))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "# define criteria and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret, label, center = cv2.kmeans(Z, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Now separate the data, Note the flatten()\n",
    "A = Z[label.ravel() == 0]\n",
    "B = Z[label.ravel() == 1]\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(A[:, 0], A[:, 1])\n",
    "plt.scatter(B[:, 0], B[:, 1], c='r')\n",
    "plt.scatter(center[:, 0], center[:, 1], s=80, c='y', marker='s')\n",
    "plt.xlabel('Height'), plt.ylabel('Weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/2/24 下午3:17\n",
    "# @Author  : play4fun\n",
    "# @File    : 48.2.3_颜色量化.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "48.2.3_颜色量化.py:\n",
    "\"\"\"\n",
    "\n",
    "# 颜色量化就是减少图片中颜色数目的一个过程。为什么 减少图片中的  色呢 减少内存消耗 有些 备的 源有  只能显示很少的 色。在 种情 况下就     \n",
    "#色 化。我们使用 K 值聚类的方法来   色 化。\n",
    "# 没有什么新的知   介绍了。现在有 3 个特征 R G B。所以我们   把图片数据变形成 Mx3 M 是图片中像素点的数目 的向 。聚类完成后  我们用聚\n",
    "#类中心值替换与其同组的像素值  样结果图片就只含有指定数目的  色了。下 是代码\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('img/home.jpg')\n",
    "# img = cv2.imread('../data/opencv_logo.png')\n",
    "Z = img.reshape((-1, 3))\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "# K = 8\n",
    "# K = 3\n",
    "K = 14\n",
    "ret, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "cv2.imshow('res2', res2)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/2/24 下午3:17\n",
    "# @Author  : play4fun\n",
    "# @File    : 48.2.3_颜色量化.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "48.2.3_颜色量化.py:\n",
    "\"\"\"\n",
    "\n",
    "#  色 化就是减少图片中 色数目的一个 程。为什么 减少图片中的  色呢 减少内存消耗 有些 备的 源有  只能显示很少的 色。在 种情 况下就     色 化。\n",
    "#我们使用 K 值聚类的方法来   色 化。\n",
    "# 没有什么新的知   介绍了。现在有 3 个特征 R G B。所以我们   把图片数据变形成 Mx3 M 是图片中像素点的数目 的向 。聚类完成后  我们用聚类中心\n",
    "#值替换与其同组的像素值  样结果图片就只含有指定数目的  色了。下 是代码\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('img/home.jpg')\n",
    "# img = cv2.imread('../data/opencv_logo.png')\n",
    "Z = img.reshape((-1, 3))\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 8\n",
    "# K = 3\n",
    "# K = 14\n",
    "ret, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "#分离颜色\n",
    "for y in range(len(center)):\n",
    "    a1 = []\n",
    "    for i,x in enumerate(label.ravel()):\n",
    "        if x==y:\n",
    "            a1.append(list(Z[i]))\n",
    "        else:\n",
    "            a1.append([0,0,0])\n",
    "    a2=np.array(a1)\n",
    "    a3=a2.reshape((img.shape))\n",
    "    cv2.imshow('res2'+str(y), a3)\n",
    "\n",
    "#最大的色块\n",
    "\n",
    "\n",
    "\n",
    "# # Now convert back into uint8, and make original image\n",
    "# center = np.uint8(center)\n",
    "# res = center[label.flatten()]\n",
    "# res2 = res.reshape((img.shape))\n",
    "\n",
    "# cv2.imshow('res2', res2)\n",
    "# cv2.imshow('res2', a3)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午9:57\n",
    "# @Author  : play4fun\n",
    "# @File    : 2-fastNlMeansDenoisingMulti.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "2-fastNlMeansDenoisingMulti.py:\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('../data/vtest.avi')\n",
    "# create a list of first 5 frames\n",
    "img = [cap.read()[1] for i in range(5)]\n",
    "# convert all to grayscale\n",
    "gray = [cv2.cvtColor(i, cv2.COLOR_BGR2GRAY) for i in img]\n",
    "# convert all to float64\n",
    "gray = [np.float64(i) for i in gray]\n",
    "\n",
    "\n",
    "# create a noise of variance 25\n",
    "noise = np.random.randn(*gray[1].shape) * 10\n",
    "# Add this noise to images\n",
    "noisy = [i + noise for i in gray]\n",
    "# Convert back to uint8\n",
    "noisy = [np.uint8(np.clip(i, 0, 255)) for i in noisy]\n",
    "\n",
    "# Denoise 3rd frame considering all the 5 frames\n",
    "dst = cv2.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 4, 7, 35)\n",
    "\n",
    "\n",
    "plt.subplot(131), plt.imshow(gray[2], 'gray')\n",
    "plt.subplot(132), plt.imshow(noisy[2], 'gray')\n",
    "plt.subplot(133), plt.imshow(dst, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午9:56\n",
    "# @Author  : play4fun\n",
    "# @File    : 1-fastNlMeansDenoisingColored.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "1-fastNlMeansDenoisingColored.py:\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('die.png')\n",
    "img = cv2.cvtColor(img, code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "# dst2=cv2.cvtColor(dst,code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "plt.subplot(122), plt.imshow(dst)\n",
    "# plt.subplot(122), plt.imshow(dst2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2017/7/13 下午11:43\n",
    "# @Author  : play4fun\n",
    "# @File    : HDR.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "\"\"\"\n",
    "HDR.py:\n",
    "http://docs.opencv.org/3.2.0/d2/df0/tutorial_py_hdr.html\n",
    "\n",
    "了解如何从曝光序列生成和显示HDR图像。\n",
    "使用曝光融合合并曝光序列。\n",
    "\n",
    "高动态范围成像（HDRI或HDR）是一种用于成像和摄影的技术，可以重现比标准数字成像或摄影技术更大的动态光度范围。虽然人眼可以调整到广泛的光线条件，\n",
    "但大多数成像设备每通道使用8位，因此我们仅限于256级。当我们拍摄现实世界的场景时，明亮的地区可能曝光过度，而黑暗的区域可能曝光不足，所以我们\n",
    "无法使用单次曝光拍摄所有细节。HDR图像与每个通道使用超过8位（通常为32位浮点值）的图像一起使用，允许更宽的动态范围。\n",
    "\n",
    "有不同的获取HDR图像的方法，但最常见的是使用不同曝光值拍摄的场景的照片。要组合这些曝光，了解您的相机的响应功能是有用的，并且有算法来估计它。\n",
    "合并HDR图像后，必须将其转换回8位才能在通常的显示屏上进行查看。这个过程叫做tonemapping。当场景或相机的对象在拍摄之间移动时，会出现附加的复\n",
    "杂性，因为具有不同曝光的图像应该被注册和对齐。\n",
    "\n",
    "在本教程中，我们展示了两种算法（Debvec，Robertson）从曝光序列生成和显示HDR图像，并展示了一种称为曝光融合（Mertens）的替代方法，它产生低动\n",
    "态范围图像，不需要曝光时间数据。此外，我们估计对于许多计算机视觉算法具有重要价值的相机响应函数（CRF）。HDR管道的每一步都可以使用不同的算法\n",
    "和参数来实现，因此请参考参考手册来查看。\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 第一阶段只是将所有图像加载到列表中。此外，我们将需要常规HDR算法的曝光时间。注意数据类型，因为图像应为1通道或3通道8位（np.uint8），曝光时间\n",
    "#需要为float32，以秒为单位。\n",
    "# Loading exposure images into a list\n",
    "img_fn = [\"1tl.jpg\", \"2tr.jpg\", \"3bl.jpg\", \"4br.jpg\"]\n",
    "img_list = [cv2.imread(fn) for fn in img_fn]\n",
    "exposure_times = np.array([15.0, 2.5, 0.25, 0.0333], dtype=np.float32)\n",
    "\n",
    "# Merge exposures to HDR image\n",
    "# 在这个阶段，我们将曝光序列合并成一个HDR图像，显示了我们在OpenCV中的两种可能性。第一种方法是Debvec，第二种是Robertson。请注意，HDR图像的类\n",
    "#型为float32，而不是uint8，因为它包含所有曝光图像的完整动态范围。\n",
    "\n",
    "merge_debvec = cv2.createMergeDebevec()\n",
    "hdr_debvec = merge_debvec.process(img_list, times=exposure_times.copy())\n",
    "merge_robertson = cv2.createMergeRobertson()\n",
    "hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy())\n",
    "\n",
    "# Tonemap HDR image\n",
    "# 我们将32位浮点HDR数据映射到范围[0..1]。实际上，在某些情况下，值可能大于1或低于0，所以注意我们以后不得不剪切数据，以避免溢出。\n",
    "tonemap1 = cv2.createTonemapDurand(gamma=2.2)\n",
    "res_debvec = tonemap1.process(hdr_debvec.copy())\n",
    "tonemap2 = cv2.createTonemapDurand(gamma=1.3)\n",
    "res_robertson = tonemap2.process(hdr_robertson.copy())\n",
    "\n",
    "# Exposure fusion using Mertens\n",
    "# 这里我们展示了一种可以合并曝光图像的替代算法，我们不需要曝光时间。我们也不需要使用任何tonemap算法，因为Mertens算法已经给出了[0..1]范围内的结果。\n",
    "merge_mertens = cv2.createMergeMertens()\n",
    "res_mertens = merge_mertens.process(img_list)\n",
    "\n",
    "# Convert datatype to 8-bit and save\n",
    "# 为了保存或显示结果，我们需要将数据转换为[0..255]范围内的8位整数。\n",
    "res_debvec_8bit = np.clip(res_debvec * 255, 0, 255).astype('uint8')\n",
    "res_robertson_8bit = np.clip(res_robertson * 255, 0, 255).astype('uint8')\n",
    "res_mertens_8bit = np.clip(res_mertens * 255, 0, 255).astype('uint8')\n",
    "\n",
    "cv2.imwrite(\"ldr_debvec.jpg\", res_debvec_8bit)\n",
    "cv2.imwrite(\"ldr_robertson.jpg\", res_robertson_8bit)\n",
    "cv2.imwrite(\"fusion_mertens.jpg\", res_mertens_8bit)\n",
    "\n",
    "exit(0)\n",
    "\n",
    "# Estimate camera response function (CRF)\n",
    "# 相机响应功能（CRF）给出了场景辐射度与测量强度值之间的连接。如果在一些计算机视觉算法中非常重要，包括HDR算法，CRF。这里我们估计反相机响应函数并将其用于HDR合并。\n",
    "cal_debvec = cv2.createCalibrateDebevec()\n",
    "crf_debvec = cal_debvec.process(img_list, times=exposure_times)\n",
    "hdr_debvec = merge_debvec.process(img_list, times=exposure_times.copy(), response=crf_debvec.copy())\n",
    "cal_robertson = cv2.createCalibrateRobertson()\n",
    "crf_robertson = cal_robertson.process(img_list, times=exposure_times)\n",
    "hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy(), response=crf_robertson.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
